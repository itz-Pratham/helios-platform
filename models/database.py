"""SQLAlchemy database models for Helios."""
from datetime import datetime
from typing import Optional
from uuid import uuid4

from sqlalchemy import (
    Column,
    String,
    Integer,
    Float,
    Boolean,
    DateTime,
    Text,
    ForeignKey,
    Index,
)
from sqlalchemy.dialects.postgresql import UUID, JSONB, ARRAY
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func

Base = declarative_base()


class Event(Base):
    """Event model representing ingested events from cloud sources."""

    __tablename__ = "events"

    # Primary key
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)

    # Event identification
    event_id = Column(String(255), unique=True, nullable=False, index=True)
    event_type = Column(String(100), nullable=False, index=True)
    source = Column(String(50), nullable=False, index=True)  # aws, gcp, azure

    # Event data
    payload = Column(JSONB, nullable=False)
    event_metadata = Column(JSONB)

    # Timestamps
    ingested_at = Column(DateTime, default=func.now(), nullable=False, index=True)
    processed_at = Column(DateTime)

    # Extracted fields for fast queries
    # Note: In production SQL, these are GENERATED columns from payload JSONB
    # For SQLAlchemy, we don't insert them - they're auto-generated by Postgres
    # order_id = Column(String(255), Computed("(payload->>'order_id')"), index=True)
    # customer_id = Column(String(255), Computed("(payload->>'customer_id')"), index=True)

    # Indexes
    __table_args__ = (
        Index('idx_event_source_type', 'source', 'event_type'),
        Index('idx_ingested_at_desc', ingested_at.desc()),
    )

    def __repr__(self):
        return f"<Event(id={self.id}, event_type={self.event_type}, source={self.source})>"


class ReconciliationResult(Base):
    """Reconciliation result comparing events across multiple cloud sources."""

    __tablename__ = "reconciliation_results"

    # Primary key
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)

    # Reconciliation run identification
    run_id = Column(String(255), nullable=False, index=True)  # Groups results from same reconciliation run

    # Event identification
    event_id = Column(String(255), nullable=False, index=True)  # Business event ID being reconciled
    event_type = Column(String(100), nullable=False, index=True)

    # Reconciliation window
    window_start = Column(DateTime, nullable=False, index=True)
    window_end = Column(DateTime, nullable=False)

    # Overall status
    status = Column(String(50), nullable=False, index=True)
    # Possible values:
    # - "consistent": Event found in all expected sources with matching data
    # - "missing": Event missing from one or more sources
    # - "inconsistent": Event found but data mismatches across sources
    # - "duplicate": Multiple copies of same event in one source
    # - "out_of_order": Event sequence violation detected

    # Source comparison
    expected_sources = Column(ARRAY(Text))  # ['aws', 'gcp', 'azure']
    found_in_sources = Column(ARRAY(Text))  # ['aws', 'gcp']
    missing_from_sources = Column(ARRAY(Text))  # ['azure']

    # Event data comparison
    event_instances = Column(JSONB)
    # {
    #   "aws": {"id": "uuid", "payload": {...}, "ingested_at": "..."},
    #   "gcp": {"id": "uuid", "payload": {...}, "ingested_at": "..."}
    # }

    # Detected issues
    issues = Column(JSONB)
    # [
    #   {"type": "missing", "source": "azure", "severity": "high"},
    #   {"type": "data_mismatch", "field": "amount", "values": {"aws": 100, "gcp": 99}, "severity": "critical"}
    # ]

    # Metrics
    consistency_score = Column(Float)  # 0.0-1.0, calculated based on issues
    latency_ms = Column(Integer)  # Time taken for reconciliation

    # Timestamps
    created_at = Column(DateTime, default=func.now(), nullable=False, index=True)
    reconciled_at = Column(DateTime)

    # Indexes
    __table_args__ = (
        Index('idx_reconciliation_run_status', 'run_id', 'status'),
        Index('idx_reconciliation_event_id', 'event_id'),
        Index('idx_reconciliation_created_at_desc', created_at.desc()),
        Index('idx_reconciliation_status_severity', 'status', 'created_at'),
    )

    def __repr__(self):
        return f"<ReconciliationResult(event_id={self.event_id}, status={self.status}, score={self.consistency_score})>"


class SelfHealingAction(Base):
    """Self-healing action triggered by the platform."""

    __tablename__ = "self_healing_actions"

    # Primary key
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)

    # Action details
    action_type = Column(String(100), nullable=False, index=True)  # scale_consumers, replay_dlq, etc.
    trigger_reason = Column(String(255), nullable=False)
    triggered_by = Column(String(50))  # auto, manual, user@example.com

    # Target details (JSONB for flexibility)
    target = Column(JSONB)  # {"topic": "events.payments", "from_replicas": 2, "to_replicas": 4}

    # Status
    status = Column(String(50), nullable=False, index=True)  # pending, in_progress, completed, failed

    # Timestamps
    triggered_at = Column(DateTime, default=func.now(), nullable=False, index=True)
    completed_at = Column(DateTime)
    duration_ms = Column(Integer)

    # Results
    success = Column(Boolean)
    error_message = Column(Text)

    # Indexes
    __table_args__ = (
        Index('idx_action_type_status', 'action_type', 'status'),
        Index('idx_triggered_at_desc', triggered_at.desc()),
    )

    def __repr__(self):
        return f"<SelfHealingAction(action_type={self.action_type}, status={self.status})>"


class ReplayHistory(Base):
    """History of event replay operations."""

    __tablename__ = "replay_history"

    # Primary key
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)

    # Replay identification
    replay_id = Column(String(255), unique=True, nullable=False, index=True)

    # Replay parameters
    start_time = Column(DateTime, nullable=False)
    end_time = Column(DateTime, nullable=False)
    filters = Column(JSONB)  # {"event_type": "OrderPlaced", "order_id": "ORD-123"}
    target_env = Column(String(50))  # sandbox, production

    # Results
    events_count = Column(Integer)
    status = Column(String(50), index=True)  # pending, in_progress, completed, failed

    # Metadata
    initiated_by = Column(String(255))
    initiated_at = Column(DateTime, default=func.now(), nullable=False, index=True)
    completed_at = Column(DateTime)

    # Indexes
    __table_args__ = (
        Index('idx_replay_status', 'status'),
        Index('idx_initiated_at_desc', initiated_at.desc()),
    )

    def __repr__(self):
        return f"<ReplayHistory(replay_id={self.replay_id}, status={self.status})>"
